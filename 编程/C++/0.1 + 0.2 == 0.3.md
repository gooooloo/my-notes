#2020-12

# 问题

`C++` 代码如下:

``` C++
#include <iostream>

int main () {
  std::cout << (0.1f + 0.2f == 0.3f) << std::endl;
  std::cout << (0.1 + 0.2 == 0.3) << std::endl;
  return 0;
}
```

`g++` 版本如下

``` console
$ g++ -v
...
Target: x86_64-linux-gnu
...
gcc version 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04)
```

执行结果如下

``` console
$ g++ a.cpp && ./a.out
1
0
```

为何 `double` 和 `float` 结果不同？

# 调查

其实浮点数的精确性本来就不确定。但为了看得更清楚，我们看下这几个数的二进制表示：

``` C++
#include <bitset>
#include <climits>
#include <iostream>
#include <stdio.h>

union FFF {
  float f;
  int i;
};

void myprintf (float v) {
  FFF data;

  data.f = v;
  std::bitset<sizeof (float) * CHAR_BIT> bits (data.i);
  printf ("%.40f -->", data.f);
  std::cout << bits << std::endl;
}

union DDD {
  double d;
  long long ll;
};

void myprintd (double v) {
  DDD data;

  data.d = v;
  std::bitset<sizeof (double) * CHAR_BIT> bits (data.ll);
  printf ("%.40lf -->", data.d);
  std::cout << bits << std::endl;
}

int main () {
  std::cout << (0.1f + 0.2f == 0.3f) << std::endl;
  myprintf (0.1f);
  myprintf (0.2f);
  myprintf (0.1f + 0.2f);
  myprintf (0.3f);

  std::cout << std::endl;

  std::cout << (0.1 + 0.2 == 0.3) << std::endl;
  myprintd (0.1);
  myprintd (0.2);
  myprintd (0.1 + 0.2);
  myprintd (0.3);

  return 0;
}
```

``` console
$ g++ a.cpp && ./a.out
1
0.1000000014901161193847656250000000000000 --> 00111101110011001100110011001101
0.2000000029802322387695312500000000000000 --> 00111110010011001100110011001101
0.3000000119209289550781250000000000000000 --> 00111110100110011001100110011010
0.3000000119209289550781250000000000000000 --> 00111110100110011001100110011010

0
0.1000000000000000055511151231257827021182 --> 0011111110111001100110011001100110011001100110011001100110011010
0.2000000000000000111022302462515654042363 --> 0011111111001001100110011001100110011001100110011001100110011010
0.3000000000000000444089209850062616169453 --> 0011111111010011001100110011001100110011001100110011001100110100
0.2999999999999999888977697537484345957637 --> 0011111111010011001100110011001100110011001100110011001100110011
```

可知 `double` 的版本，`0.1 + 0.2` 和 `0.3` 差了一个点位。

# 汇编

``` console
$ cat a.cpp && g++ -S a.cpp && echo '----' && cat a.s
#include <iostream>

int main () {
  std::cout << (0.1f + 0.2f == 0.3f) << (0.1 + 0.2 == 0.3);
  return 0;
}
----
...
main:
...
        movl    $1, % esi                 ;; <--- (0.1f + 0.2f == 0.3f) 变成了 1
        leaq    _ZSt4cout (% rip), % rdi
        call    _ZNSolsEb@PLT
        movl    $0, % esi                 ;; <--- (0.1 + 0.2 == 0.3) 变成了 0
        movq    % rax, % rdi
        call    _ZNSolsEb@PLT
...
```

可知其实这个计算在编译期就确定了。这个技术叫常量折叠 (constant folding)

# 编译器的常量折叠是怎么计算浮点数加法和比较的？

以 `gcc 9.3.0` 为例，它自己用软件实现了浮点数按位加减法。

`gcc` 自己的浮点数数据结构在 [gcc/real.h at releases/gcc-9.3.0・gcc-mirror/gcc (github.com)](https://github.com/gcc-mirror/gcc/blob/releases/gcc-9.3.0/gcc/real.h)

``` C++
//https://github.com/gcc-mirror/gcc/blob/4212a6a3e44f870412d9025eeb323fd4f50a61da/gcc/real.h#L33-L50
#define SIGNIFICAND_BITS	(128 + HOST_BITS_PER_LONG)
#define EXP_BITS		(32 - 6)
#define MAX_EXP			((1 << (EXP_BITS - 1)) - 1)
#define SIGSZ			(SIGNIFICAND_BITS / HOST_BITS_PER_LONG)
#define SIG_MSB			((unsigned long) 1 << (HOST_BITS_PER_LONG - 1))

struct GTY (()) real_value {
  /* Use the same underlying type for all bit-fields, so as to make
     sure they're packed together, otherwise REAL_VALUE_TYPE_SIZE will
     be miscomputed.  */
  unsigned int /* ENUM_BITFIELD (real_value_class) */cl : 2;
  unsigned int decimal : 1;
  unsigned int sign : 1;
  unsigned int signalling : 1;
  unsigned int canonical : 1;
  unsigned int uexp : EXP_BITS;
  unsigned long sig [SIGSZ];
};
```

有趣的是，这里用于保存小数位（`fraction`）的 `sig` 用了 3 个 long 也就是 192 bit （在 64 位上），保存指数位的 `uexp` 用了 26 bit；对比 [IEEE 754 - Wikipedia](https://en.wikipedia.org/wiki/IEEE_754) 的 32 位 `float`，`fraction` 是 23 bit，`exp` 是 8 bit； [IEEE 754 - Wikipedia](https://en.wikipedia.org/wiki/IEEE_754) 的 64 位 `double`，`fraction` 是 52 bit， `exp` 是 11 bit。

`gcc` 自己实现的加法和比较在  [gcc/real.c at releases/gcc-9.3.0・gcc-mirror/gcc (github.com)](https://github.com/gcc-mirror/gcc/blob/releases/gcc-9.3.0/gcc/real.c) 

``` C++
//https://github.com/gcc-mirror/gcc/blob/4212a6a3e44f870412d9025eeb323fd4f50a61da/gcc/real.c#L261-L288

/* Add the significands of A and B, placing the result in R.  Return
   true if there was carry out of the most significant word.  */
static inline bool
add_significands (REAL_VALUE_TYPE *r, const REAL_VALUE_TYPE *a,
		  const REAL_VALUE_TYPE *b)
{
  bool carry = false;
  int i;

  for (i = 0; i < SIGSZ; ++i)
    {
      unsigned long ai = a->sig [i];
      unsigned long ri = ai + b->sig [i];

      if (carry)
		{
	  		carry = ri < ai;
			carry |= ++ri == 0;
		}
      else carry = ri < ai;

      r->sig [i] = ri;
    }

  return carry;
}
```

``` C++
//https://github.com/gcc-mirror/gcc/blob/4212a6a3e44f870412d9025eeb323fd4f50a61da/gcc/real.c#L348-L367

/* Compare significands.  Return tri-state vs zero.  */
static inline int
cmp_significands (const REAL_VALUE_TYPE *a, const REAL_VALUE_TYPE *b)
{
  int i;

  for (i = SIGSZ - 1; i >= 0; --i)
    {
      unsigned long ai = a->sig [i];
      unsigned long bi = b->sig [i];

      if (ai > bi)	return 1;
      if (ai < bi)	return -1;
    }

  return 0;
}
```

